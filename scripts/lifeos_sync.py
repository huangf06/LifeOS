#!/usr/bin/env python3
"""
LifeOS è‡ªåŠ¨åŒæ­¥å¼•æ“
OmniFocus â†” Logseq åŒå‘åŒæ­¥
"""

import json
import subprocess
import re
from datetime import datetime, date, timedelta
from pathlib import Path
import uuid
import sys
import argparse

class LifeOSSync:
    def __init__(self, logseq_graph_path="~/logseq", lifeos_path="~/LifeOS"):
        self.logseq_path = Path(logseq_graph_path).expanduser()
        self.lifeos_path = Path(lifeos_path).expanduser()
        self.journals_path = self.logseq_path / "journals"
        self.data_path = self.lifeos_path / "data"
        self.scripts_path = self.lifeos_path / "scripts"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.data_path.mkdir(parents=True, exist_ok=True)
        self.journals_path.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ Logseqè·¯å¾„: {self.logseq_path}")
        print(f"ğŸ“ æ•°æ®è·¯å¾„: {self.data_path}")
    
    def morning_sync(self):
        """æ™¨é—´åŒæ­¥ï¼šOmniFocus â†’ Logseq"""
        print("ğŸŒ… å¼€å§‹æ™¨é—´åŒæ­¥...")
        
        try:
            # 1. ä» OmniFocus å¯¼å‡ºä»»åŠ¡
            tasks = self.export_omnifocus_tasks()
            print(f"ğŸ“± ä» OmniFocus å¯¼å‡ºäº† {len(tasks)} ä¸ªä»»åŠ¡")
            
            # 2. ç”Ÿæˆ Logseq æ—¥å¿—å†…å®¹
            today = date.today()
            journal_content = self.generate_logseq_journal(tasks, today)
            
            # 3. æ›´æ–° Logseq æ—¥å¿—é¡µé¢
            self.update_logseq_journal(journal_content, today)
            
            # 4. ä¿å­˜åŒæ­¥è®°å½•
            self.save_sync_record("morning", len(tasks))
            
            print("âœ… æ™¨é—´åŒæ­¥å®Œæˆï¼")
            self.send_notification("æ™¨é—´åŒæ­¥å®Œæˆ", f"å·²å¯¼å…¥ {len(tasks)} ä¸ªä»»åŠ¡")
            
        except Exception as e:
            print(f"âŒ æ™¨é—´åŒæ­¥å¤±è´¥: {e}")
            self.send_notification("åŒæ­¥å¤±è´¥", str(e))
    
    def export_omnifocus_tasks(self):
        """ä» OmniFocus å¯¼å‡ºä»»åŠ¡"""
        script_path = self.scripts_path / "omnifocus_export.scpt"
        
        if not script_path.exists():
            raise FileNotFoundError(f"OmniFocuså¯¼å‡ºè„šæœ¬ä¸å­˜åœ¨: {script_path}")
        
        # è¿è¡Œ AppleScript
        result = subprocess.run(
            ['osascript', str(script_path)], 
            capture_output=True, 
            text=True,
            timeout=30
        )
        
        if result.returncode != 0:
            raise Exception(f"OmniFocuså¯¼å‡ºå¤±è´¥: {result.stderr}")
        
        # è¯»å–å¯¼å‡ºçš„JSONæ–‡ä»¶
        export_file = self.data_path / "omnifocus_export.json"
        
        if not export_file.exists():
            raise FileNotFoundError("OmniFocuså¯¼å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
        
        with open(export_file, 'r', encoding='utf-8') as f:
            tasks = json.load(f)
        
        return tasks
    
    def generate_logseq_journal(self, tasks, target_date):
        """ç”Ÿæˆ Logseq æ—¥å¿—å†…å®¹"""
        weekday_name = target_date.strftime('%A')
        date_str = target_date.strftime('%Y-%m-%d')
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºä»»åŠ¡
        high_priority_tasks = [t for t in tasks if t.get('flagged', False)]
        regular_tasks = [t for t in tasks if not t.get('flagged', False)]
        
        # ç”Ÿæˆä»»åŠ¡åˆ—è¡¨
        task_list = ""
        
        if high_priority_tasks:
            task_list += "\n### ğŸ”¥ é«˜ä¼˜å…ˆçº§ä»»åŠ¡\n"
            for task in high_priority_tasks:
                task_list += self.format_task_for_logseq(task) + "\n"
        
        if regular_tasks:
            task_list += "\n### ğŸ“‹ å¸¸è§„ä»»åŠ¡\n" 
            for task in regular_tasks:
                task_list += self.format_task_for_logseq(task) + "\n"
        
        # ç”Ÿæˆæ—¶é—´è§„åˆ’è¡¨æ ¼
        time_blocks = self.generate_time_blocks(tasks)
        
        template = f"""# {date_str} | {weekday_name} | %energy: /10

## ğŸ¯ ä»Šæ—¥æ„å›¾
*æˆ‘ä»Šå¤©è¦æˆä¸ºä»€ä¹ˆæ ·çš„äººï¼Œåšä»€ä¹ˆæœ€é‡è¦çš„äº‹ï¼Ÿ*



## ğŸ“‹ ä»»åŠ¡åˆ—è¡¨ (ä»OmniFocusåŒæ­¥ - {len(tasks)}é¡¹)
{task_list}

## â° æ—¶é—´è§„åˆ’
{time_blocks}

---

## ğŸ“ æ‰§è¡Œè®°å½•

### {datetime.now().strftime('%H:%M')} - å¼€å§‹å·¥ä½œ
@focus: /10 @energy: /10
> å…³é”®æƒ³æ³•ï¼š


---

## ğŸ§  å­¦ä¹ æ•è·
**å­¦åˆ°ä»€ä¹ˆæ–°ä¸œè¥¿ï¼š**

**ç»ƒä¹ äº†ä»€ä¹ˆæŠ€èƒ½ï¼š**

**æœ‰ä»€ä¹ˆè®¤çŸ¥æ›´æ–°ï¼š**

---

## ğŸŒ™ æ™šé—´åæ€ (%satisfaction: /10)

### ä»Šæ—¥æˆå°±
âœ… 
âœ… 
âœ… 

### ä¸»è¦æŒ‘æˆ˜
â— 

### æ˜æ—¥é‡ç‚¹
ğŸ¯ 
ğŸ¯ 
ğŸ¯ 

### æœ€æœ‰ä»·å€¼çš„æ”¶è·
> 

---

## ğŸ“Š ä»»åŠ¡åŒæ­¥çŠ¶æ€
%morning_sync: {datetime.now().strftime('%H:%M')}
%evening_sync: pending
%total_tasks: {len(tasks)}
%completed_tasks: 0

---
%writing_time: min | %word_count: words
"""
        return template
    
    def format_task_for_logseq(self, task):
        """æ ¼å¼åŒ–å•ä¸ªä»»åŠ¡ä¸º Logseq æ ¼å¼"""
        # åŸºç¡€ä¿¡æ¯
        name = task.get('name', 'Untitled')
        project = task.get('project', 'Inbox')
        context = task.get('context', '')
        estimated = task.get('estimatedMinutes', 0)
        
        # æ„å»ºæ ‡è®°
        project_tag = f"`[{project}]`" if project != 'Inbox' else ""
        context_tag = f"@{context}" if context else ""
        time_tag = f"â±ï¸{estimated}min" if estimated > 0 else ""
        
        # ä¼˜å…ˆçº§å›¾æ ‡
        priority_icon = "ğŸ”¥ " if task.get('flagged', False) else ""
        
        # ä»»åŠ¡IDï¼ˆç”¨äºåŒæ­¥ï¼‰
        task_id = task.get('id', str(uuid.uuid4())[:8])
        
        # ç»„åˆæ ¼å¼
        parts = [priority_icon + name, project_tag, context_tag, time_tag, f"&of:{task_id}"]
        formatted_parts = [part for part in parts if part]
        
        return f"- [ ] {' '.join(formatted_parts)}"
    
    def generate_time_blocks(self, tasks):
        """ç”Ÿæˆæ—¶é—´å—åˆ†é…è¡¨æ ¼"""
        total_estimated = sum(task.get('estimatedMinutes', 30) for task in tasks)
        high_priority_tasks = [t for t in tasks if t.get('flagged', False)]
        
        if total_estimated == 0:
            return """| æ—¶é—´ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ |
|------|------|----------|
| 09:00-12:00 | æ·±åº¦å·¥ä½œ | 3h |
| 13:30-15:30 | å¸¸è§„ä»»åŠ¡ | 2h |
| 16:00-17:30 | æ²Ÿé€šåè°ƒ | 1.5h |"""
        
        time_blocks = "| æ—¶é—´ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ |\n|------|------|----------|\n"
        
        # ä¸ºé«˜ä¼˜å…ˆçº§ä»»åŠ¡å®‰æ’ä¸Šåˆæ—¶é—´
        morning_start = 9
        for i, task in enumerate(high_priority_tasks[:3]):  # æœ€å¤š3ä¸ªé«˜ä¼˜å…ˆçº§ä»»åŠ¡
            duration = task.get('estimatedMinutes', 60)
            hours = duration // 60
            minutes = duration % 60
            time_str = f"{hours}h{minutes}min" if minutes > 0 else f"{hours}h"
            
            start_time = morning_start + i * 2
            end_time = start_time + max(1, duration // 60)
            
            time_blocks += f"| {start_time:02d}:00-{end_time:02d}:00 | {task['name'][:20]}... | {time_str} |\n"
        
        # ä¸‹åˆæ—¶é—´å—
        time_blocks += "| 13:30-15:30 | å…¶ä»–é‡è¦ä»»åŠ¡ | 2h |\n"
        time_blocks += "| 16:00-17:30 | æ²Ÿé€šåè°ƒ | 1.5h |\n"
        
        return time_blocks
    
    def update_logseq_journal(self, content, target_date):
        """æ›´æ–° Logseq æ—¥å¿—é¡µé¢"""
        journal_file = self.journals_path / f"{target_date.strftime('%Y_%m_%d')}.md"
        
        if journal_file.exists():
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåªæ›´æ–°ä»»åŠ¡éƒ¨åˆ†
            existing_content = journal_file.read_text(encoding='utf-8')
            
            # æŸ¥æ‰¾ä»»åŠ¡åˆ—è¡¨éƒ¨åˆ†å¹¶æ›¿æ¢
            pattern = r'(## ğŸ“‹ ä»»åŠ¡åˆ—è¡¨.*?)(## â° æ—¶é—´è§„åˆ’)'
            new_task_section = re.search(r'(## ğŸ“‹ ä»»åŠ¡åˆ—è¡¨.*?)(## â° æ—¶é—´è§„åˆ’)', content, re.DOTALL)
            
            if new_task_section and re.search(pattern, existing_content, re.DOTALL):
                updated_content = re.sub(
                    pattern, 
                    new_task_section.group(0), 
                    existing_content, 
                    flags=re.DOTALL
                )
                journal_file.write_text(updated_content, encoding='utf-8')
                print(f"ğŸ“ å·²æ›´æ–°ç°æœ‰æ—¥å¿—: {journal_file}")
            else:
                # å¦‚æœæ‰¾ä¸åˆ°æ¨¡å¼ï¼Œç›´æ¥è¦†ç›–
                journal_file.write_text(content, encoding='utf-8')
                print(f"ğŸ“ å·²è¦†ç›–æ—¥å¿—æ–‡ä»¶: {journal_file}")
        else:
            # åˆ›å»ºæ–°æ–‡ä»¶
            journal_file.write_text(content, encoding='utf-8')
            print(f"ğŸ“ å·²åˆ›å»ºæ–°æ—¥å¿—: {journal_file}")
    
    def evening_sync(self):
        """æ™šé—´åŒæ­¥ï¼šLogseq â†’ OmniFocus"""
        print("ğŸŒ™ å¼€å§‹æ™šé—´åŒæ­¥...")
        
        try:
            # 1. ä» Logseq æå–ä»»åŠ¡çŠ¶æ€æ›´æ–°
            today = date.today()
            task_updates = self.extract_task_updates_from_logseq(today)
            
            if not task_updates:
                print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°ä»»åŠ¡çŠ¶æ€æ›´æ–°")
                return
            
            print(f"ğŸ“ æå–äº† {len(task_updates)} ä¸ªä»»åŠ¡çŠ¶æ€æ›´æ–°")
            
            # 2. åŒæ­¥çŠ¶æ€åˆ° OmniFocus
            success_count = 0
            for task_id, status, notes in task_updates:
                if self.update_omnifocus_task(task_id, status, notes):
                    success_count += 1
            
            print(f"âœ… æˆåŠŸåŒæ­¥ {success_count}/{len(task_updates)} ä¸ªä»»åŠ¡")
            
            # 3. ä¿å­˜åŒæ­¥è®°å½•
            self.save_sync_record("evening", success_count)
            
            self.send_notification("æ™šé—´åŒæ­¥å®Œæˆ", f"å·²åŒæ­¥ {success_count} ä¸ªä»»åŠ¡çŠ¶æ€")
            
        except Exception as e:
            print(f"âŒ æ™šé—´åŒæ­¥å¤±è´¥: {e}")
            self.send_notification("åŒæ­¥å¤±è´¥", str(e))
    
    def extract_task_updates_from_logseq(self, target_date):
        """ä» Logseq æ—¥å¿—ä¸­æå–ä»»åŠ¡çŠ¶æ€æ›´æ–°"""
        journal_file = self.journals_path / f"{target_date.strftime('%Y_%m_%d')}.md"
        
        if not journal_file.exists():
            print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {journal_file}")
            return []
        
        content = journal_file.read_text(encoding='utf-8')
        updates = []
        
        # åŒ¹é…ä¸åŒçŠ¶æ€çš„ä»»åŠ¡
        patterns = {
            'completed': r'- \[x\] .+?&of:(\w+).*',
            'cancelled': r'- \[-\] .+?&of:(\w+).*',
            'deferred': r'- \[>\] .+?&of:(\w+).*'
        }
        
        for status, pattern in patterns.items():
            matches = re.findall(pattern, content, re.MULTILINE)
            for task_id in matches:
                # æå–ç›¸å…³å¤‡æ³¨
                task_line_pattern = rf'- \[.\] .+?&of:{re.escape(task_id)}.*'
                task_match = re.search(task_line_pattern, content)
                notes = ""
                
                if task_match:
                    task_line = task_match.group(0)
                    # æå–è´¨é‡è¯„åˆ†ç­‰ä¿¡æ¯
                    quality_match = re.search(r'âœ¨.*?(\d+/10)', task_line)
                    if quality_match:
                        notes += f"è´¨é‡è¯„åˆ†: {quality_match.group(1)}\n"
                    
                    # æå–å…¶ä»–å¤‡æ³¨
                    note_match = re.search(r'âœ¨(.+?)(?=\s|$)', task_line)
                    if note_match:
                        notes += f"æ‰§è¡Œå¤‡æ³¨: {note_match.group(1)}\n"
                
                updates.append((task_id, status, notes.strip()))
        
        return updates
    
    def update_omnifocus_task(self, task_id, status, notes=""):
        """æ›´æ–° OmniFocus ä»»åŠ¡çŠ¶æ€"""
        try:
            if status == 'completed':
                script = f'''
                tell application "OmniFocus 3"
                    set theTask to (first flattened task of default document whose id is "{task_id}")
                    set completed of theTask to true
                    if "{notes}" is not "" then
                        set note of theTask to (note of theTask) & "\\n\\nLogseq sync: {notes}"
                    end if
                end tell
                '''
            elif status == 'cancelled':
                script = f'''
                tell application "OmniFocus 3"
                    set theTask to (first flattened task of default document whose id is "{task_id}")
                    set completed of theTask to true
                    set note of theTask to (note of theTask) & "\\n\\n[CANCELLED] " & "{notes}"
                end tell
                '''
            elif status == 'deferred':
                tomorrow = (date.today() + timedelta(days=1)).strftime('%Y-%m-%d')
                script = f'''
                tell application "OmniFocus 3"
                    set theTask to (first flattened task of default document whose id is "{task_id}")
                    set defer date of theTask to date "{tomorrow}"
                    set note of theTask to (note of theTask) & "\\n\\nDeferred from Logseq: " & "{notes}"
                end tell
                '''
            else:
                return False
            
            result = subprocess.run(
                ['osascript', '-e', script], 
                capture_output=True, 
                text=True,
                timeout=10
            )
            
            if result.returncode == 0:
                print(f"âœ… ä»»åŠ¡ {task_id} çŠ¶æ€æ›´æ–°ä¸º {status}")
                return True
            else:
                print(f"âŒ æ›´æ–°ä»»åŠ¡ {task_id} å¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"âŒ æ›´æ–°ä»»åŠ¡ {task_id} æ—¶å‡ºé”™: {e}")
            return False
    
    def save_sync_record(self, sync_type, count):
        """ä¿å­˜åŒæ­¥è®°å½•"""
        record = {
            "timestamp": datetime.now().isoformat(),
            "type": sync_type,
            "count": count,
            "date": date.today().isoformat()
        }
        
        log_file = self.data_path / "sync_log.jsonl"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(record) + "\n")
    
    def send_notification(self, title, message):
        """å‘é€ç³»ç»Ÿé€šçŸ¥"""
        script = f'''
        display notification "{message}" with title "LifeOS - {title}" sound name "Glass"
        '''
        
        try:
            subprocess.run(['osascript', '-e', script], timeout=5)
        except:
            pass  # å¿½ç•¥é€šçŸ¥å¤±è´¥
    
    def status(self):
        """æ˜¾ç¤ºåŒæ­¥çŠ¶æ€"""
        print("ğŸ“Š LifeOS åŒæ­¥çŠ¶æ€")
        print("-" * 30)
        
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
        print(f"Logseq Graph: {self.logseq_path}")
        print(f"æ•°æ®ç›®å½•: {self.data_path}")
        
        # æ£€æŸ¥æœ€è¿‘çš„åŒæ­¥è®°å½•
        log_file = self.data_path / "sync_log.jsonl"
        if log_file.exists():
            with open(log_file, 'r') as f:
                lines = f.readlines()
                if lines:
                    last_record = json.loads(lines[-1])
                    print(f"æœ€ååŒæ­¥: {last_record['timestamp']}")
                    print(f"åŒæ­¥ç±»å‹: {last_record['type']}")
                    print(f"å¤„ç†ä»»åŠ¡: {last_record['count']} ä¸ª")


def main():
    parser = argparse.ArgumentParser(description='LifeOS è‡ªåŠ¨åŒæ­¥å·¥å…·')
    parser.add_argument('action', choices=['morning', 'evening', 'status'], 
                       help='æ‰§è¡Œçš„æ“ä½œ')
    parser.add_argument('--logseq-path', default='~/logseq',
                       help='Logseq Graph è·¯å¾„')
    parser.add_argument('--lifeos-path', default='~/LifeOS',
                       help='LifeOS æ•°æ®è·¯å¾„')
    
    args = parser.parse_args()
    
    sync = LifeOSSync(args.logseq_path, args.lifeos_path)
    
    if args.action == 'morning':
        sync.morning_sync()
    elif args.action == 'evening':
        sync.evening_sync()
    elif args.action == 'status':
        sync.status()


if __name__ == "__main__":
    main()